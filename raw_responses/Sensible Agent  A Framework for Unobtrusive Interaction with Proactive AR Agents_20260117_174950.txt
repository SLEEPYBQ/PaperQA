Document: Sensible Agent  A Framework for Unobtrusive Interaction with Proactive AR Agents.md
Timestamp: 20260117_174950
================================================================================

## computational_modelling
Answer: Formative Study; Design goals/requirements: adapt both “what” assistance to offer and “how” to deliver it based on real-time context (including social setting, urgency, familiarity, and situational I/O constraints), using a taxonomy of action categories and context variants derived from an expert workshop and a data annotation study.
Source: “Informed by an expert workshop (n=12) and a data annotation study (n=40), the framework leverages egocentric cameras, multimodal sensing, and Large Multimodal Models (LMMs) to infer context and suggest appropriate actions delivered via minimally intrusive interaction modes.”; “Both modules are guided by a taxonomy of action categories and context variants derived from our study, enabling structured conditioning of LLM outputs and policy decisions.”; “We outline five key design implications that directly informed our framework: (1) The same activity may require different proactive behaviors based on contextual variants… (2) Social engagement and public settings significantly constrain interaction modalities… (3) Temporarily impaired input/output channels are common in everyday settings… Our framework integrates this insight into the how module… (4) Users welcome suggestion diversity when uncertain, but prefer precision when familiar… (5) Embedded, multimodal confirmations lower friction in high-effort scenarios.”; “This study informed the core reasoning mechanism of our system by providing grounded examples of context-action-modality mappings, which were later used to condition an LLM through incontext learning.”