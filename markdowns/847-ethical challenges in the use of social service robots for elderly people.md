Z Gerontol Geriat 2016 · 49:303–307 DOI 10.1007/s00391-016-1066-5 Received: 18 January 2016 Revised: 29 February 2016 Accepted: 15 March 2016 Published online: 25 May 2016 © Springer-Verlag Berlin Heidelberg 2016

![](_page_0_Picture_2.jpeg)

#### **T. Körtner**

Akademie für Altersforschung am Haus der Barmherzigkeit, Wien, Österreich

# **Ethical challenges in the use of social service robots for elderly people**

## **Introduction**

We do not discuss ethics when it comes to coffee machines or television sets, so why for robots? Looking at the prognosis of the demographic development and the rising numbers of older people in need of care [\[7\]](#page-4-0), hopes are placed on technical solutions for the increasing demands on care. One idea is to use social service robots (SSR) for supporting senior adults. Due to the increasing autonomy and ability to learn of suchmachines, ethical questions become more and more evident. This article aims to provide a brief overview of the major issues identified so far.

## **Why ethics in robotics?**

Meet Henry! An autonomous and mobile robot platform with a green covering and anthropomorphic features roams through the corridors of an Austrian care institution. Henry is part of the European science project STRANDS. The robot patrols corridors, offers information on a touchscreen, can be called to the reception to guide visitors to offices and accompanies physiotherapy walking groups, playing music and stimulating participants suffering from dementia by means of sounds and a picture gallery. Most members of staff and patients see a real robot for the first time. Robots operating in environments alongside human beings or evenaimingforinteraction with human beings raise complex issues. Such social service or personal companion robots become more and more autonomous, theyare often connected tointernet services and can collect, store and transmit potentially private data. Some robotscanevenlearnabout theirenvironment and reach autonomous decisions, like Henry. Coupled with tendencies to make assistive robots more human-like in looks and behavior, a huge field for debates and ethical discussions is opened up.

## **Ethical principles**

So, what could ethical principles in robotics be? First of all, ethics are not to be equated with morality. Morality judges human actions based on a differentiation between good and evil. Ethics is the theory of morality or rather an ethos. In ethics, moral values are critically analyzed. Ethos can be individual and is strongly linked to the person and his or her attitudes [\[14\]](#page-4-1). Ethics should constantly reflect what is best for society and ethics can also change [\[27\]](#page-4-2). Operto [\[19\]](#page-4-3) suggested that roboethics (i. e. ethics applied for the identification and analysis of ethical issues that arise from current and upcoming robotics applications) should adhere to the Universal Declaration of Human Rights and the Treaty of Lisbon (2000), which are the basis of human dignity for every human being. The concept of dignity in Western cultures is strongly tied to Kant and his concept of human dignity being beyond any value. Respect for other human beings, the right of every human being to exist and general equality of all human beings constitute these principles of human dignity. In other words, it describes the recognition of the fundamental values of every other human being [\[16\]](#page-4-4). This inherent dignity of every human being is enshrined in the Declaration of Human Rights and also, for example, in the German Constitution.

Kitchener and Anderson [\[13\]](#page-4-5) presented the foundations of ethical principles. These are:

- 1. Nonmaleficence
- 2. Beneficence (i. e. the interests of the user and person need to be addressed)
- 3. Respect for personal autonomy and
- 4. Fairness (in distributing resources).

Feil-SeiferandMataric [\[9\]](#page-4-6) concluded that core ethical principles are necessarywhen developing and applying assistive robotic systems. These refer to the principles of biomedical ethics [\[2\]](#page-4-7), which also list beneficence, nonmaleficence, autonomy, justice and fairness. Arguably, all these principles would also be desirable in socially assistive robots; however, situations can easily occur where, strictly speaking, such principles cannot be met: as a scientific platform Henry is not tested for all situations and is prone to errors, so even if beneficence is the objective it might not always be achieved. Henry has a touchscreen suitable for people standing but not necessarily for older persons sitting in wheelchairs. Fair accessibility is therefore obviously not given for all persons in every situation. This shows that even with the best intentions in mind ethical challenges can quickly arise; however, technology cannot progress without testing in real-world environments. In order to know what users regard as helpful and how they can operate the robot, prototypes have to be tested with (sometimes)

#### **Beiträge zum Themenschwerpunkt**

vulnerable groups. This adds to the ethical dimensions of robot deployments as will be discussed in the following section.

## **Ethical risks of robotics for older people**

Robots in care of the elderly are hoped to bring benefits for everyone involved [\[23\]](#page-4-8) but risks are also addressed. In the literature and also from experience in the Spatio-Temporal Representations and Activities for Cognitive Control in Long-Term Scenarios (STRANDS) project, recurring aspects are deception, dignity, isolation, data protection, privacy and safety.

**Deception.** What a robot looks like, the height and design already produce expectations regarding its functionality or even its level of intelligence [\[12\]](#page-4-9). Speech is another key factor. Robots are able to produce (preprogrammed) speech or even recognize human speech. They can be machine-like in their interaction or can produce polite, more personalized dialogues and thus have different robot "personalities" [\[20\]](#page-4-10). We observed that Henry, when he was first deployed at the care site was often expected to be able to engage in natural conversation and to understand human language. As this was not the case, people were quickly frustrated by failing to communicate with the robot. Other robots are designed to display emotional responses [\[5\]](#page-4-11). The more autonomous and complex robots become, the more the line between a machine and a living person might become blurred. Especially vulnerable persons (e. g. children and older persons) who interact with a robot might project emotionalfacultiesinto amachine that are not there. Turkle [\[26\]](#page-4-12), for instance, observed that aged participants in a study formed emotional attachments to a robot. This, however, caused wrong theories about the cognitive and emotional capabilities of the robot. Some participantswereworried that the robotwouldmiss themwhen they left their homes. This leads to the questionwhether such robots are a device of deception [\[24\]](#page-4-13). A machine deceiving a person would be unethical. After all, one should not forget that robots are (so far) incapable of consciousness or emotional

**304 Zeitschrift für Gerontologie und Geriatrie 4 · 2016**

states. On the other hand, we are all able to anthropomorphize objects (from dolls to motorcars), which is "the tendency to imbue the real or imagined behavior of nonhuman agents with humanlike characteristics, motivations, intentions, or emotions" [\[8\]](#page-4-14). The issues of expectations and deception cannot therefore be easily ignored. The consequences of anthropomorphization for older persons could be, for example, stress or placing false trust in a machine.

**Dignity.** In the care and therapy of elderly persons the most prominent robot to be found at the moment is the PARO robotic seal. The objective is usually to engage patients with dementia in interaction and thus activate and motivate them [\[28\]](#page-4-15); however, what is overlooked in such studies are novelty effects, improvement brought on by group activities in general and also the problem of patronizing or infantilization of senior adults suffering from dementia. Infantilization in this vulnerable group and thus violating fundamental human rights, is considered to be ethically wrong in geriatrics [\[10\]](#page-4-16). The same discussion is valid for Henry to some extent: when patients of a physiotherapy walking group follow him through the corridors and sing to the traditional songs the robot is playing, are they being infantilized or is there an emotional benefit and activation experienced by these patients? For the time being the use and benefit of therapeutic robots in elderly care and dementia has to be left open to discussion.

**Isolation.** Isolation is seen as a main reason for resisting the use of robots, especially among older persons [\[21\]](#page-4-17). Social care of vulnerable persons is left to machines. The more we can communicate with robots, the less we might communicate with human beings, especially senior adults who are impaired in their mobility. While there is evidence that human social networks and companionship help to delay the onset of dementia, long-term experience and evidence with robots is lacking [\[24\]](#page-4-13). Instead, the danger of reducing interpersonal communication by using robots instead of humans for care tasks needs to be acknowledged. Where this outweighs the aim of increasing independence, the use of robots for senior adults becomes unethical [\[25\]](#page-4-18). Other developers and engineers argue for the possibilities of robots and other assistive devices to even promote and improve communication between human beings [\[4\]](#page-4-19).

**Privacy.** In times of closed-circuit television (CCTV) and worldwide connections via the internet, the borders between public and private information are more flexible and thus also harder to define. In order to gain benefits we give away personal information and robots for senior adults are no exception. In order to navigate and detect obstacles or persons, Henry is equipped with cameras and able to store video data. Video data and images are processed and also sometimes even stored by other robots. Apart from that, sensors are used on robots to detect movements or measure activities. Users, however, cannot always control what happens with such data. This opens a wider ethical debate: it has been found that persons with a greater need for care are more willing to give up their privacy. Even though recording vital signs or toilet behavior with cameras was least acceptable, sensor technology is acceptable to a great number of people [\[1\]](#page-4-20). Such results suggest that older persons might be led to accept and get used to robots transferring personal information without further scrutinization. It follows that in order for older individuals to gain autonomy by means of robotic devices they should be provided with a basic understanding of the technology. Systems of data collection and storage need to be transparent [\[29\]](#page-4-21). It has to be made clear what data is recorded when and who has access to it. In Henry's institutional setting, not only the interest of senior patients but maybe also care staff and visitors, who might feel monitored by a robot, need to be addressed. Even then privacy and data protection cannot be guaranteed. Denning et al. [\[6\]](#page-4-22)found that simple domestic robots could be easilylocated andidentified by a remote party and also hacked and even controlled or operated. With bigger, more complex robots, internet security and safety of personal data of users seems to be an even greater challenge. Loss of control and autonomy is seen as leading to feelings of objectification [\[24\]](#page-4-13), which once more emphasizes the importance of being in control of the robot and not vice versa. In the private sphere, informed consent is one tool to address privacy issues. When operating in a public or semi-public space, registration of the robot with the data protection agency in charge, as was done with Henry and adherence to data protection laws might be an additional step.

**Safety.**Robots might cause damage. This is not intended (apart from maybe military applications) but cannot be ruled out, especially where robots are still not used as a product but as a prototype. When roaming the corridors, Henry once turned around a corner and collided with apersonpushingapatientinawheelchair. Another time he fell down a staircase. Who is liable in cases when damage is caused by an autonomous robot? Is it the engineer, the designer, the company that produced the robot or should this be the responsibility of the users themselves? Could a robot itself be liable? One suggestion is to take out an insurance against harm caused by (autonomous) robots [\[18\]](#page-4-23); however, currently it is relatively unlikely to find an insurance company willing to do this, especially when talking about a research prototype. The issue of liability is something to keep companies and researchers busy in the future. In addition, the subjective feeling of safety of a person encountering a robot should not be overlooked. Even though a robot might fulfil safety standards, a person in a wheelchair, for example, might feel endangered when the robot is moving past without keeping a certain distance away.

**Vulnerability.** The general vulnerability of older persons as participants in robotic research or as users of assistive robots needs to be addressed. As long as they understand the purpose of a technology and are able to communicate their intentions, persons can give informed consent. What, however, happens if a robot is used for persons with dementia or if a person who gave consent loses the ability to reason? Where persons without the capa-

### **Abstract · Zusammenfassung**

Z Gerontol Geriat 2016 · 49:303–307 DOI 10.1007/s00391-016-1066-5 © Springer-Verlag Berlin Heidelberg 2016

#### **T. Körtner**

# **Ethical challenges in the use of social service robots for elderly people**

#### **Abstract**

Socially assistive robots are increasingly discussed as solutions in care and domestic use for the support of senior adults; however, this raises ethical questions which hitherto have not been considered or were not predictable. The most important questions are those of privacy and data protection, safety and responsibility as well as involvement of vulnerable persons and deception. Consequently, the ethical principles of nonmaleficence, beneficence, autonomy and fairness should be transposed to robotics. Clear answers and solutions are

not yet available for every ethical challenge in robotics; however, the development of ethical guidelines for deployment of robots and research in the field of social service robots (SSR) are essential steps in order to embed ethics into dealing with socially assistive robots. This article provides some practical suggestions on this issue from a robotics project.

#### **Keywords**

Robotics · Ethics · Vulnerable persons · Informed consent · Assistive technology

## **Ethische Herausforderungen zum Einsatz sozial-assistiver Roboter bei älteren Menschen**

#### **Zusammenfassung**

Sozial-assistive Roboter in der Pflege oder für den Heimgebrauch werden zunehmend als Lösungen zur Unterstützung älterer Menschen diskutiert. Sie werfen jedoch ethische Fragen auf, die bisher nicht angedacht oder vorhersehbar waren. Die wichtigsten sind: Fragen zu Privatsphäre und Datenschutz, zu Sicherheit, Verantwortlichkeit und zum Umgang mit vulnerablen Personen sowie die Frage der Täuschung. Ethische Grundsätze von Nichtschaden, Fürsorge, Autonomie und Fairness sollten dementsprechend auch auf die Robotik umgelegt werden. Nicht für alle ethischen Herausforderungen gibt es

in der Robotik bereits klare Antworten. Die Ausarbeitung von Richtlinien zum Einsatz von Robotern oder auch zur Forschung im Bereich "social service robots" (SSR) ist jedoch ein wichtiger Schritt, um Ethik im Umgang mit sozial-assistiven Robotern zu verankern. Der vorliegende Beitrag trägt hierzu einige praktische Vorschläge aus einem Robotikprojekt bei.

#### **Schlüsselwörter**

Robotik · Ethik · Vulnerable Personen · "Informed consent" · Assistive Technologie

bility to consent are concerned, at least an informed consent by proxy should be sought. This can be a time-consuming procedure and needs to be established in due time before introducing any technical devices. Even then it should be noted that a proxy is usually not authorized to decide on participation in a scientific study [\[15\]](#page-4-24). Where there is no clear regulation, a waiver of consent in any case, just like in clinical studies should clearly reason the risk for the vulnerable person in comparison to the expected benefits [\[3\]](#page-4-25).

Finally, a research process as such might be stressful for participants. Using an assistive robot can make handicapped or older individuals aware of their personal limitations, which in turn might lead to negative feelings, anxiety or exhaustion with those participants. Ethical conduct in SSR research therefore always needs to involve the human angle: introducing a robot does affect persons in their feelings and their daily life.

# **Ethical guidelines for deploying robots**

The issues discussed in this article cannot be regarded as a full in-depth coverage of all ethical topics in research or deployment of robots for older persons. As can also be seen, ethical debates raise

#### **Beiträge zum Themenschwerpunkt**

questions for which immediate answers are not always available. It is difficult to predict how new technology will develop and what that means for society; however, the need for guidelines has been acknowledged. Guidelines for the general use of assistive technologies (including robots) have been issued by Manzeschke et al. [\[17\]](#page-4-26) and both Ingram et al. [\[11\]](#page-4-27) and Riek and Howard [\[22\]](#page-4-28) have proposed ethical guidelines for robotic engineers. Again, the issues of privacy, vulnerability, safety and deception are very globally addressed. Based on the experience of Henry in the field, additional, more practical comments can be made for care institution settings:

**Deception.** Informing senior adults in a comprehensible way about the real capabilities and limitations of robots is essential. Time should be devoted to such informative talks. The reactions of patients with severe dementia cannot be anticipated in advance. Careful cooperation with medical and care staff is suggested in order to avoid anxiety or stress for patients.

**Dignity.** In the case of dementia patients, theissue of dignity should be linked to the deployment of a robot, i. e. is it respectful to confront persons who cannot cognitively grasp the concept and use of a robot with such a machine? This will depend on the area in which the robot is used and its function. Those involved and responsible for the robot should continuously reflect ethical issues. If need be, the summoning of an internal ethics board can help to facilitate this process, especially where dignity of dementia patients in connection with tasks the robot fulfils or interaction with a robot are concerned. This has been done in the STRANDS project, where members of different professions from the care site constituted an ethics board. Furthermore, involving staff and/or relatives early on can help to identify ethical issues, misunderstandings and also requirements and expectations. Information events, workshops and being available forfeedback and contact are recommended ways to keep in touch with those who are affected by the robot.

**Privacy.** Deactivation of video functions of the robot in private and sensitive areas. This has to be discussed withmedical staff. For Henry, it was decided not to capture video data in the care site outpatient area, where patients are treated and often wait in beds. When using robots at home users should be given the opportunity to clearly indicate where no video data should be captured.

**Informed consent.**With a huge area covered by Henry where various people are coming and going, informed consent is not feasible; however, easily available information leaflets and posters about the robot, the use of data and the purpose of the deployment should be placed in the area in which the robot is operating. Local laws should be referred to in detail. For Austria, a lengthy registration with the Austrian Data Protection Agency was necessary in order to receive approval for deploying a mobile robot with video camera to capture data in a care hospital. It is highly recommended to thoroughly study data protection regulations or seek external advice.

**Safety.** Pilot testing is crucial before deploying a robot in a care setting; however, obstacles and navigation failure may occur that could not be expected. Where safety of patients or staff is concerned either navigation needs to be improved or alternative areas where the robot can move need to be discussed. No-go zones should be defined with staff before an actual deployment. The behavior of robots should be predictable for persons. Feedback from staff and patients should be soughtfor improving robot predictability to avoid confusion and accidents.

**Data protection.** Apart from legal registration or approval from ethics boards, the use of data collected by the robot as well as safe and anonymous storage have to be planned before a deployment (e. g. password protected hard drives that are not connected to the internet or other networks and blurring of faces in published images and videos).

**Vulnerability.** The perception of vulnerable persons, their needs, theirlimited resilience and also limited experience with technology have to be at the centre of deployments of SSRs. Enthusiasm for what is technically possible or might be helpful with a robotic assistant should never cause limits in stress tolerance to be overlooked or simple acceptance by vulnerable users. Not every technological solution is suitable for everyone. Deliberate choices not to use a robot or certain functions always need to be respected.

# **Conclusion**

Ethics should be a fundamental part of (socially) assistive robots and their deployment

- 4 The main areas where ethical reflection is decisive are: privacy, data protection, safety and also the question whether the functionalities of a robot might not tend to lead to isolation, loss of autonomy, overstressing of users and/or deception.
- Ethical questions might not always be immediately answered and could serve to trigger a process of reflection. For some questions, legal regulations might exist. This, however, does not necessarily mean that what is legal is also ethically sound.
- Different robots might evoke different ethical discussions and requirements based on its functions, design and the setting in which it is used; therefore, it is highly recommended that ethical guidelines should be analyzed, followed and expanded. This should be a continuous process that also has to involve end users and caregivers.
- Ethics can lead to changes or obstacles in both scientific and practical deployments. Ethics, however, should not be treated as slowing down research and technical possibilities. Instead, ethics should be incorporated in order to develop more helpful devices for older people. Ultimately, ethical considerations in robotics for senior citizens should not only ask what view we have on technology but also what image of humanity prevails in robotics.

#### **Corresponding address**

![](_page_4_Picture_1.jpeg)

#### **Dr. T. Körtner**

Akademie für Altersforschung am Haus der Barmherzigkeit Seeböckgasse 30a, 1160 Wien, Österreich tobias.koertner@ altersforschung.ac.at

**Funding.** Parts of the research leading to these results and guidelines received funding from the European Community's Seventh Framework Programme under grant agreement No. 600623, STRANDS [\(http://strands.acin.tuwien.ac.at/\)](http://strands.acin.tuwien.ac.at/).

# **Compliance with ethical guidelines**

**Conflict of interest.** T. Körtner states that there are no conflicts of interest.

The accompanying manuscript does not include studies on humans or animals.

## **References**

- <span id="page-4-20"></span>1. Beach S, Schulz R, Downs J, Matthews J, Barron B, SeelmanK(2009)Disability,age,andinformational privacy attitudes in quality of life technology applications: Results from a national web survey. ACMTrans Access Comput2(1):1–21
- <span id="page-4-7"></span>2. Beauchamp TL, Childress JF (2009) Principles of Biomedical Ethics, 6th edn. Oxford University Press,Oxford
- <span id="page-4-25"></span>3. Bioethikkommission des Bundeskanzleramts Österreich(2013) Research on Personswithout the capacity to consent – with special consideration of the concept of risk. Geschäftsstelle der Bioethikkommission,Wien
- <span id="page-4-19"></span>4. Borenstein J, Pearson Y (2010) Robot caregivers: harbingers of expanded freedom for all? Ethics Inf Technol12(3):277–288
- <span id="page-4-11"></span>5. Broekens J, Heerink M, Rosendal H (2009) Assistive social robots in elderly care: a review. Gerontechnology8(2):94–103
- <span id="page-4-22"></span>6. Denning T, Matuszek C, Koscher K, Smith JR, Kohno T (2009) A spotlight on security and privacy risks with future household robots: attacks and lessons. In: Proceedings of the 11th international conference on Ubiquitous computing 11th international conference on Ubiquitous computing., pp105–114
- <span id="page-4-0"></span>7. EuropeanCommission(2015)DemographyReport –2015 Edition. PublicationsOfficeof the European Union, Luxembourg.
- <span id="page-4-14"></span>8. EpleyN,Waytz A, Cacioppo JT(2007)On seeing human: a three-factor theory of anthropomorphism. Psychol Rev114(4):864–886
- <span id="page-4-6"></span>9. Feil-Seifer D, Mataric MJ (2011) Socially Assistive Robotics. IEEE RobotAutomMag2011:24–31
- <span id="page-4-16"></span>10. Frühwald T(2012) Ethik in der Geriatrie.Z Gerontol Geriatr45(6):545–557
- <span id="page-4-27"></span>11. Ingram B, Jones D, Lewis A, Richards M, Rich C, Schachterle L (2010) A code of ethics for robotics engineers. In: Proceedings of the 5th ACM/

IEEE International Conference on Human-Robot Interaction(HRI)

- <span id="page-4-9"></span>12. Kanda T, Ishiguro H, Imai M, Ono T (2004) Development and evaluation of interactive humanoid robots. ProcIEEE92(11):1839–1850
- <span id="page-4-5"></span>13. Kitchener KS, Anderson SK (2011) Foundations of ethical practice, research, and teaching in psychology and counseling, 2nd edn. Routledge, NewYork, London
- <span id="page-4-1"></span>14. Körtner UHJ (2015) Ehik, Moral. In: Evangelische Ethik Kompakt. Gütersloher Verlagshaus, Gütersloh, pp33–40
- <span id="page-4-24"></span>15. Kothgassner OD, Weber D, Felnhofer A (2011) Geroethics: Ethische Aspekte im Umgang mit assistiven Technologien und altersbedingten Erkrankungen. In: Kryspin-ExnerI, KothgassnerOD (eds) Ethik in der Psychologie. Facultas.wuv, Wien, pp148–159
- <span id="page-4-26"></span><span id="page-4-4"></span>16. Lebech M (2004) What is human dignity? MaynoothPhilosPap, Issue2 :59–69
- 17. Manzeschke A, Weber K, Rother E, Fangerau H (2013) Ergebnisse der Studie "Ethische Fragen im Bereich Altersgerechter Assistenzsysteme". VDI/VDE, Ludwigsfelde
- <span id="page-4-23"></span>18. Matthias A(2004)The responsibility gap: Ascribing responsibilityfor the actionsoflearning automata. Ethics InfTechnol6(3):175–183
- <span id="page-4-10"></span><span id="page-4-3"></span>19. Operto F (2011) Ethics in advanced robotics. IEEE RobotAutomMag1(18):72–78
- 20. Panek P, Mayer P, Schuller F, Zagler WL (2015) Beiträge zur Modellierung von "Persönlichkeit" bei assistiven Robotern für alte Menschen zwecks besserer Mensch-Roboter Interaktion. In: AAL-Kongress2015. VDE, Berlin
- <span id="page-4-17"></span>21. Parks JA(2010) Lifting the burden ofWomen's Care Work: Should Robots Replace the "Human Touch"? Hypatia25:100–120
- <span id="page-4-28"></span>22. Riek LD, Howard D (2014) A code of ethics for the human-robot interaction profession WeRobot 2014 Conference. UniversityofMiami,
- <span id="page-4-8"></span>23. Sharkey A, Sharkey N (2011) Children, the Elderly, and Interactive Robots. IEEE Robot Autom Mag 18:32–38
- <span id="page-4-18"></span><span id="page-4-13"></span>24. Sharkey N, Sharkey A (2012) The eldercare factory. Gerontology58(3):282–288
- 25. Sparrow R, Sparrow L (2006) In the hands of machines? The future of aged care. Minds Mach 16(2):141–161
- <span id="page-4-12"></span>26. Turkle, S (2006) Relational artifacts with children and elders: The complexities of cybercompanions. ConnectionScience18(4):347–361.
- <span id="page-4-2"></span>27. Velasquez M, Andre C, Shanks T, Meyer MJ, Meyer MJ(1987)Whatis ethics. Issues Ethics1(1):1–2
- <span id="page-4-15"></span>28. Wada K, Shibata T, Saito T, Sakamoto K, Tanie K (2005) Psychological and social effects of one year robotassistedactivityonelderly people ata health service facility for the aged. In: Proceedings of the 2005 IEEE International Conference on IEEE. ICRA, pp2785–2790
- <span id="page-4-21"></span>29. Wagner I (2010) Forschungsethik in der Technikentwicklung. In: Körtner U, Kopetzki C, Druml C (eds) Ethik und Recht in der Humanforschung. Springer,WienNewYork, pp257–272

Hier steht eine Anzeige. K

![](_page_4_Picture_40.jpeg)